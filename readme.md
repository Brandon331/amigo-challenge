# üß† Research Agent - S√≠ntesis de Conocimiento Multi-Agente

Este proyecto es un sistema de IA multi-agente dise√±ado para acelerar la investigaci√≥n. En lugar de simplemente resumir texto, este sistema utiliza un equipo de agentes de IA especializados que leen, analizan y *debaten* activamente las fuentes de conocimiento (PDFs, arXiv, Wikipedia) para generar insights colectivos.

El resultado final se presenta en un **mapa de conocimiento interactivo** que visualiza las conexiones entre los papers, los conceptos clave y, lo m√°s importante, los fragmentos espec√≠ficos de la discusi√≥n de los agentes, haciendo que su razonamiento sea completamente transparente y verificable.

## üöÄ Caracter√≠sticas Principales

* **Ingesta de Conocimiento Multi-Fuente:** Procesa autom√°ticamente PDFs subidos, art√≠culos de **arXiv** y p√°ginas de **Wikipedia** para construir una base de conocimiento.
* **Extracci√≥n de Conceptos por LLM:** Utiliza **GPT-4o-mini** para analizar cada fuente y extraer conceptos clave, hallazgos principales y puntos de datos.
* **Debate Multi-Agente:** Un equipo de agentes especializados (analista matem√°tico, soci√≥logo, analista f√≠sico y analista general) debate la pregunta del usuario bas√°ndose en el conocimiento ingerido.
* **Visualizaci√≥n de Grafo Interactivo:** Genera un mapa conceptual din√°mico con **`vis.js`** que muestra las relaciones entre los papers, los conceptos y los hallazgos.
* **Estilo de "Boceto" Org√°nico:** El grafo est√° estilizado para parecer un mapa conceptual "dibujado a mano" en una pizarra, con colores pastel y fuentes manuscritas.
* **Razonamiento Verificable ("Tent√°culos"):** ¬°Haz clic en un concepto clave en el mapa y aparecer√° un "tent√°culo" con el fragmento exacto de la discusi√≥n donde los agentes hablaron sobre ese tema!
* **Generaci√≥n de Reportes PDF:** Exporta la discusi√≥n completa, el resumen de ingesta y las referencias a un reporte cient√≠fico formal en PDF usando **ReportLab**.

## üíª Pila Tecnol√≥gica

* **Backend:**
    * **Python 3.10+**
    * **FastAPI:** Para servir la API REST.
    * **OpenAI GPT-4o-mini:** Como el cerebro para los agentes, extracci√≥n y an√°lisis.
    * **LangChain:** Para la orquestaci√≥n de documentos (loaders, splitters).
    * **Hugging Face Embeddings:** Para generar los vectores de `all-MiniLM-L6-v2`.
    * **ChromaDB:** Como la base de datos vectorial en memoria.
    * **ReportLab:** Para la generaci√≥n de reportes en PDF.
* **Frontend:**
    * **HTML5, CSS3, JavaScript (ES6+)**
    * **Vis.js (vis-network):** Para el renderizado del grafo interactivo.
    * **Kalam (Google Font):** Para el estilo "dibujado a mano".

## üèóÔ∏è C√≥mo Funciona (Arquitectura)

1.  **Entrada:** El usuario proporciona un *prompt* (pregunta) y/o un archivo PDF a trav√©s del frontend (`mapa.html`).
2.  **API Backend:** La solicitud llega al endpoint `/ask` de **FastAPI** (`main.py`).
3.  **Ingesta (`KnowledgeIngestion`):**
    * El sistema procesa el PDF (si se proporcion√≥).
    * Si `auto_search` est√° activo, busca en **arXiv** y **Wikipedia** usando el prompt del usuario.
    * Para cada documento, llama a GPT-4o-mini (`_extract_key_concepts`) para obtener un JSON de `key_concepts` y `main_findings`.
4.  **Orquestaci√≥n (`Orchestrator`):**
    * Todo el texto se vectoriza y se almacena en **ChromaDB**.
    * El `Orchestrator` realiza una b√∫squeda sem√°ntica para encontrar los fragmentos m√°s relevantes para la pregunta del usuario.
    * Los agentes de IA (Brandon, Rodrigo, etc.) reciben este contexto e inician un debate por rondas (`run_discussion`).
5.  **An√°lisis del Debate:**
    * Una vez que el debate termina, una funci√≥n (`_analyze_debate_insights`) vuelve a llamar a GPT-4o-mini, pas√°ndole el debate completo y los conceptos clave.
    * La IA extrae los "fragmentos de debate" (`debate_snippet`) que se relacionan con cada concepto.
6.  **Generaci√≥n del Grafo:**
    * La funci√≥n `generate_graph_data` crea el JSON para el mapa conceptual, inyectando los `debate_snippet` en los nodos de "concepto" correspondientes.
7.  **Respuesta:**
    * El backend env√≠a el JSON completo (discusi√≥n, metadata, `graph_data`) al frontend.
    * El frontend (`mapa.html`) usa `vis.js` para dibujar el mapa con el estilo "Kalam" y activa los *event listeners* para la funcionalidad de "tent√°culos" al hacer clic.

## üõ†Ô∏è Instalaci√≥n y Ejecuci√≥n Local

Sigue estos pasos para correr el proyecto en tu m√°quina local.

### 1. Backend (FastAPI)

1.  **Clona el repositorio:**
    ```bash
    git clone [URL-DE-TU-REPOSITORIO]
    cd toon_project
    ```

2.  **Crea y activa un entorno virtual:**
    ```bash
    # Windows
    python -m venv .venv
    .\.venv\Scripts\Activate.ps1
    
    # macOS / Linux
    python3 -m venv .venv
    source .venv/bin/activate
    ```

3.  **Instala las dependencias de Python:**
    ```bash
    pip install fastapi "uvicorn[standard]" openai "langchain-community" "langchain-huggingface" \
    langchain-core "unstructured[pdf]" arxiv wikipedia chromadb sentence-transformers reportlab
    ```

4.  **Configura tu API Key:**
    * **Opci√≥n A (Recomendada):** Crea una variable de entorno.
        ```bash
        # Windows (PowerShell)
        $env:OPENAI_API_KEY = "sk-..."
        
        # macOS / Linux
        export OPENAI_API_KEY="sk-..."
        ```
    * **Opci√≥n B (Fallback):** Abre `main.py` y reemplaza el valor de `api_key` (l√≠nea 504 aprox.) con tu llave de OpenAI.

5.  **Ejecuta el servidor:**
    (Aseg√∫rate de que tu archivo se llame `main.py`)
    ```bash
    uvicorn main:app --reload
    ```
    El servidor estar√° corriendo en `http://127.0.0.1:8000`.

### 2. Frontend (HTML/JS)

1.  **Abre `mapa.html`:** No necesitas instalaci√≥n. Simplemente abre el archivo `mapa.html` en tu navegador.
2.  **(Recomendado)** Para evitar problemas de CORS, usa una extensi√≥n como **"Live Server"** en VS Code. Haz clic derecho en `mapa.html` y selecciona "Open with Live Server".

## ü§ù Equipo y Contribuciones

Este proyecto fue desarrollado por un equipo de analistas e ingenieros:

* **Rodrigo (Ingeniero de Conocimiento y Visualizaci√≥n):** Soy Rodrigo, estoy en tercer semestre de la licenciatura en inform√°tica en la UNAM, y particip√© en este proyecto como Ingeniero de Conocimiento y Visualizaci√≥n. Mi rol fue construir el "cerebro" del sistema: desarroll√© el pipeline de Ingesti√≥n de Conocimiento que lee y analiza PDFs complejos, transformando el texto para extraer autom√°ticamente los conceptos clave que los agentes necesitan para razonar. Adem√°s, dise√±√© y program√© el mapa conceptual interactivo, la interfaz visual principal. Este mapa no solo muestra los hallazgos, sino que tambi√©n hace "verificable" el razonamiento de los agentes, conectando los fragmentos de sus discusiones directamente a los conceptos en la pantalla.
* **Brandon** (Analista Cient√≠fico Matem√°tico)
* **Esve** (Analista Cient√≠fico F√≠sico)
* **Emmanuel** (Analista Cient√≠fico General)

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT.
